import os
import urllib.request
from pathlib import Path

def download_file(url, filepath):
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§"""
    try:
        print(f"Downloading {filepath}...")
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        urllib.request.urlretrieve(url, filepath)
        print(f"âœ… Downloaded: {filepath}")
    except Exception as e:
        print(f"âŒ Error downloading {filepath}: {e}")

def create_project_structure():
    """Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø±ÙˆÚ˜Ù‡ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§"""
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
    folders = ['css', 'js/libs', 'js/models', 'sounds']
    for folder in folders:
        Path(folder).mkdir(parents=True, exist_ok=True)
        print(f"âœ… Created folder: {folder}")
    
    # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§
    libraries = {
        'js/libs/face-api.min.js': 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js',
        'js/libs/tracking-min.js': 'https://cdn.jsdelivr.net/npm/tracking@1.1.3/build/tracking-min.js'
    }
    
    for filepath, url in libraries.items():
        download_file(url, filepath)
    
    # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Face-API
    base_model_url = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/'
    models = [
        'tiny_face_detector_model-weights_manifest.json',
        'tiny_face_detector_model-shard1',
        'face_landmark_68_model-weights_manifest.json',
        'face_landmark_68_model-shard1',
        'face_recognition_model-weights_manifest.json',
        'face_recognition_model-shard1',
        'face_recognition_model-shard2'
    ]
    
    for model in models:
        download_file(base_model_url + model, f'js/models/{model}')
    
    # Ø§ÛŒØ¬Ø§Ø¯ index.html
    html_content = '''<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ø¯ÙˆØ±Ø¨ÛŒÙ†</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸ”’ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ø¯ÙˆØ±Ø¨ÛŒÙ†</h1>
            <div class="status" id="status">Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ...</div>
        </header>

        <div class="controls">
            <button id="switchCamera" class="btn">ğŸ”„ ØªØºÛŒÛŒØ± Ø¯ÙˆØ±Ø¨ÛŒÙ†</button>
            <button id="startBtn" class="btn btn-primary">â–¶ Ø´Ø±ÙˆØ¹</button>
            <button id="stopBtn" class="btn btn-danger">â¹ ØªÙˆÙ‚Ù</button>
        </div>

        <div class="video-container">
            <video id="video" autoplay playsinline muted></video>
            <canvas id="overlay"></canvas>
        </div>

        <div class="stats">
            <div class="stat-item">
                <span class="stat-label">Ø§ÙØ±Ø§Ø¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:</span>
                <span class="stat-value" id="totalPeople">0</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">Ø¯ÙˆØ±Ø¨ÛŒÙ† ÙØ¹Ø§Ù„:</span>
                <span class="stat-value" id="currentCamera">Ø¬Ù„Ùˆ</span>
            </div>
        </div>

        <div class="gallery">
            <h2>ğŸ“¸ Ú¯Ø§Ù„Ø±ÛŒ ØªØµØ§ÙˆÛŒØ±</h2>
            <div id="gallery" class="gallery-grid"></div>
        </div>
    </div>

    <audio id="alarm" loop>
        <source src="sounds/alarm.mp3" type="audio/mpeg">
    </audio>

    <script src="js/libs/face-api.min.js"></script>
    <script src="js/libs/tracking-min.js"></script>
    <script src="js/app.js"></script>
</body>
</html>'''
    
    with open('index.html', 'w', encoding='utf-8') as f:
        f.write(html_content)
    print("âœ… Created: index.html")
    
    # Ø§ÛŒØ¬Ø§Ø¯ style.css
    css_content = '''* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    min-height: 100vh;
    padding: 20px;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    background: white;
    border-radius: 20px;
    box-shadow: 0 20px 60px rgba(0,0,0,0.3);
    overflow: hidden;
}

header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 30px;
    text-align: center;
}

header h1 {
    font-size: 2rem;
    margin-bottom: 10px;
}

.status {
    display: inline-block;
    padding: 8px 20px;
    background: rgba(255,255,255,0.2);
    border-radius: 20px;
    font-size: 0.9rem;
}

.controls {
    display: flex;
    gap: 15px;
    padding: 20px;
    justify-content: center;
    flex-wrap: wrap;
}

.btn {
    padding: 12px 30px;
    border: none;
    border-radius: 10px;
    font-size: 1rem;
    cursor: pointer;
    transition: all 0.3s;
    font-weight: bold;
}

.btn-primary {
    background: #10b981;
    color: white;
}

.btn-primary:hover {
    background: #059669;
    transform: translateY(-2px);
}

.btn-danger {
    background: #ef4444;
    color: white;
}

.btn-danger:hover {
    background: #dc2626;
    transform: translateY(-2px);
}

.btn:active {
    transform: translateY(0);
}

.video-container {
    position: relative;
    max-width: 640px;
    margin: 0 auto;
    background: #000;
    border-radius: 10px;
    overflow: hidden;
}

#video {
    width: 100%;
    height: auto;
    display: block;
}

#overlay {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    pointer-events: none;
}

.stats {
    display: flex;
    justify-content: space-around;
    padding: 30px;
    background: #f8fafc;
    flex-wrap: wrap;
    gap: 20px;
}

.stat-item {
    text-align: center;
}

.stat-label {
    display: block;
    color: #64748b;
    font-size: 0.9rem;
    margin-bottom: 5px;
}

.stat-value {
    display: block;
    font-size: 2rem;
    font-weight: bold;
    color: #667eea;
}

.gallery {
    padding: 30px;
}

.gallery h2 {
    color: #1e293b;
    margin-bottom: 20px;
    text-align: center;
}

.gallery-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
    gap: 20px;
}

.gallery-item {
    position: relative;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    transition: transform 0.3s;
}

.gallery-item:hover {
    transform: scale(1.05);
}

.gallery-item img {
    width: 100%;
    height: 200px;
    object-fit: cover;
}

.gallery-item .info {
    position: absolute;
    bottom: 0;
    left: 0;
    right: 0;
    background: linear-gradient(to top, rgba(0,0,0,0.8), transparent);
    color: white;
    padding: 10px;
    font-size: 0.8rem;
}

@media (max-width: 768px) {
    header h1 {
        font-size: 1.5rem;
    }
    
    .controls {
        flex-direction: column;
    }
    
    .btn {
        width: 100%;
    }
    
    .gallery-grid {
        grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));
    }
}'''
    
    with open('css/style.css', 'w', encoding='utf-8') as f:
        f.write(css_content)
    print("âœ… Created: css/style.css")
    
    # Ø§ÛŒØ¬Ø§Ø¯ app.js
    js_content = '''// Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ
let video, canvas, ctx, alarm;
let stream = null;
let isRunning = false;
let currentCamera = 'user'; // 'user' = Ø¬Ù„Ùˆ, 'environment' = Ù¾Ø´Øª
let detectedPeople = [];
let modelsLoaded = false;

// Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Face-API
async function loadModels() {
    try {
        document.getElementById('status').textContent = 'Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...';
        
        await faceapi.nets.tinyFaceDetector.loadFromUri('js/models');
        await faceapi.nets.faceLandmark68Net.loadFromUri('js/models');
        await faceapi.nets.faceRecognitionNet.loadFromUri('js/models');
        
        modelsLoaded = true;
        document.getElementById('status').textContent = 'âœ… Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ù‡ Ú©Ø§Ø±';
        console.log('âœ… Models loaded successfully');
    } catch (error) {
        console.error('âŒ Error loading models:', error);
        document.getElementById('status').textContent = 'âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§';
    }
}

// Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
window.addEventListener('DOMContentLoaded', async () => {
    video = document.getElementById('video');
    canvas = document.getElementById('overlay');
    ctx = canvas.getContext('2d');
    alarm = document.getElementById('alarm');
    
    await loadModels();
    
    document.getElementById('startBtn').addEventListener('click', startDetection);
    document.getElementById('stopBtn').addEventListener('click', stopDetection);
    document.getElementById('switchCamera').addEventListener('click', switchCamera);
});

// Ø´Ø±ÙˆØ¹ Ø¯ÙˆØ±Ø¨ÛŒÙ†
async function startCamera() {
    try {
        if (stream) {
            stream.getTracks().forEach(track => track.stop());
        }
        
        const constraints = {
            video: {
                facingMode: currentCamera,
                width: { ideal: 640 },
                height: { ideal: 480 }
            },
            audio: false
        };
        
        stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        
        video.onloadedmetadata = () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
        };
        
        document.getElementById('currentCamera').textContent = 
            currentCamera === 'user' ? 'Ø¬Ù„Ùˆ' : 'Ù¾Ø´Øª';
        
        return true;
    } catch (error) {
        console.error('âŒ Camera error:', error);
        document.getElementById('status').textContent = 'âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¯ÙˆØ±Ø¨ÛŒÙ†';
        return false;
    }
}

// ØªØºÛŒÛŒØ± Ø¯ÙˆØ±Ø¨ÛŒÙ†
async function switchCamera() {
    currentCamera = currentCamera === 'user' ? 'environment' : 'user';
    if (isRunning) {
        await startCamera();
    }
}

// Ø´Ø±ÙˆØ¹ ØªØ´Ø®ÛŒØµ
async function startDetection() {
    if (!modelsLoaded) {
        alert('Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯ ØªØ§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´ÙˆÙ†Ø¯');
        return;
    }
    
    const cameraStarted = await startCamera();
    if (!cameraStarted) return;
    
    isRunning = true;
    document.getElementById('status').textContent = 'ğŸ”´ Ø¯Ø± Ø­Ø§Ù„ ØªØ´Ø®ÛŒØµ...';
    detectFaces();
}

// ØªÙˆÙ‚Ù ØªØ´Ø®ÛŒØµ
function stopDetection() {
    isRunning = false;
    if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
    }
    alarm.pause();
    alarm.currentTime = 0;
    document.getElementById('status').textContent = 'â¸ Ù…ØªÙˆÙ‚Ù Ø´Ø¯Ù‡';
    ctx.clearRect(0, 0, canvas.width, canvas.height);
}

// ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡
async function detectFaces() {
    if (!isRunning) return;
    
    try {
        const detections = await faceapi
            .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceDescriptors();
        
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        if (detections.length > 0) {
            detections.forEach(detection => {
                drawDetection(detection);
                processPerson(detection);
            });
        }
        
        requestAnimationFrame(detectFaces);
    } catch (error) {
        console.error('Detection error:', error);
        requestAnimationFrame(detectFaces);
    }
}

// Ø±Ø³Ù… Ú©Ø§Ø¯Ø± ØªØ´Ø®ÛŒØµ
function drawDetection(detection) {
    const box = detection.detection.box;
    const landmarks = detection.landmarks.positions;
    
    // Ø±Ø³Ù… Ú©Ø§Ø¯Ø±
    ctx.strokeStyle = '#00ff00';
    ctx.lineWidth = 3;
    ctx.strokeRect(box.x, box.y, box.width, box.height);
    
    // Ø±Ø³Ù… Ù†Ù‚Ø§Ø· ØµÙˆØ±Øª
    ctx.fillStyle = '#ff0000';
    landmarks.forEach(point => {
        ctx.beginPath();
        ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
        ctx.fill();
    });
}

// Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ±Ø¯ Ø¬Ø¯ÛŒØ¯
function processPerson(detection) {
    const descriptor = detection.descriptor;
    const landmarks = detection.landmarks.positions;
    const landmarkCount = landmarks.length;
    
    // Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ø§ÛŒÙ† ÙØ±Ø¯ Ù‚Ø¨Ù„Ø§Ù‹ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡
    let existingPerson = null;
    let minDistance = 0.6; // Ø¢Ø³ØªØ§Ù†Ù‡ ØªØ´Ø®ÛŒØµ (Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± = Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±)
    
    for (let person of detectedPeople) {
        const distance = faceapi.euclideanDistance(descriptor, person.descriptor);
        if (distance < minDistance) {
            minDistance = distance;
            existingPerson = person;
        }
    }
    
    if (existingPerson) {
        // Ø§Ú¯Ø± ØªØ¹Ø¯Ø§Ø¯ Ø§Ø¬Ø²Ø§ÛŒ ØµÙˆØ±Øª Ø¨ÛŒØ´ØªØ± Ø§Ø³ØªØŒ Ø¹Ú©Ø³ Ø±Ø§ Ø¨Ù‡â€ŒØ±ÙˆØ² Ú©Ù†
        if (landmarkCount > existingPerson.landmarkCount) {
            existingPerson.landmarkCount = landmarkCount;
            existingPerson.image = captureFrame();
            updateGallery();
        }
    } else {
        // ÙØ±Ø¯ Ø¬Ø¯ÛŒØ¯
        const newPerson = {
            id: Date.now(),
            descriptor: descriptor,
            landmarkCount: landmarkCount,
            image: captureFrame(),
            timestamp: new Date().toLocaleString('fa-IR')
        };
        
        detectedPeople.push(newPerson);
        updateGallery();
        playAlarm();
    }
}

// Ø¶Ø¨Ø· ÙØ±ÛŒÙ…
function captureFrame() {
    const captureCanvas = document.createElement('canvas');
    captureCanvas.width = video.videoWidth;
    captureCanvas.height = video.videoHeight;
    const captureCtx = captureCanvas.getContext('2d');
    captureCtx.drawImage(video, 0, 0);
    return captureCanvas.toDataURL('image/jpeg');
}

// Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú¯Ø§Ù„Ø±ÛŒ
function updateGallery() {
    const gallery = document.getElementById('gallery');
    gallery.innerHTML = '';
    
    detectedPeople.forEach(person => {
        const item = document.createElement('div');
        item.className = 'gallery-item';
        item.innerHTML = `
            <img src="${person.image}" alt="Person ${person.id}">
            <div class="info">
                <div>Ø²Ù…Ø§Ù†: ${person.timestamp}</div>
                <div>Ø§Ø¬Ø²Ø§ÛŒ ØµÙˆØ±Øª: ${person.landmarkCount}</div>
            </div>
        `;
        gallery.appendChild(item);
    });
    
    document.getElementById('totalPeople').textContent = detectedPeople.length;
}

// Ù¾Ø®Ø´ Ø¢Ú˜ÛŒØ±
function playAlarm() {
    alarm.play().catch(e => console.log('Alarm play error:', e));
    setTimeout(() => alarm.pause(), 3000);
}

// Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù‡Ù†Ú¯Ø§Ù… Ø¨Ø³ØªÙ†
window.addEventListener('beforeunload', () => {
    detectedPeople = [];
    stopDetection();
});'''
    
    with open('js/app.js', 'w', encoding='utf-8') as f:
        f.write(js_content)
    print("âœ… Created: js/app.js")
    
    print("\n" + "="*50)
    print("âœ… ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù†Ø¯!")
    print("="*50)
    print("\nâš ï¸ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ:")
    print("ÙØ§ÛŒÙ„ sounds/alarm.mp3 Ø±Ø§ Ø¯Ø³ØªÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯")

if __name__ == '__main__':
    create_project_structure()
